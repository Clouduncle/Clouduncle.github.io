<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>linux系统检查</title>
      <link href="/2015/07/20/linux/linux2/"/>
      <url>/2015/07/20/linux/linux2/</url>
      
        <content type="html"><![CDATA[<h4 id="系统常用检查命令"><a href="#系统常用检查命令" class="headerlink" title="系统常用检查命令"></a>系统常用检查命令</h4><p>&emsp;&emsp;磁盘：df -h<br>&emsp;&emsp;内存：free -m<br>&emsp;&emsp;负载：top</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop001 ~]$ free -m </span><br><span class="line">              total        used        free      shared  buff&#x2F;cache   available</span><br><span class="line">Mem:           7823         222        6229         257        1371        7096</span><br><span class="line">Swap:             0           0           0</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;大数据生产服务器swap是设置0。  10也可以（swap作用是将硬盘划分过来作为内存，所以当数据进入swap那么肯定是很缓慢的，所以设置为0）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop001 ~]$ df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">&#x2F;dev&#x2F;vda1        40G   16G   25G  39% &#x2F;</span><br><span class="line"></span><br><span class="line">&#x2F;dev&#x2F;vdb1        2T   16G   25G  1% &#x2F;data01</span><br><span class="line">&#x2F;dev&#x2F;vdb2        2T   16G   25G  1% &#x2F;data02</span><br><span class="line">&#x2F;dev&#x2F;vdb3        2T   16G   25G  1% &#x2F;data03</span><br><span class="line">&#x2F;dev&#x2F;vdb4        2T   16G   25G  1% &#x2F;data04</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">不要</span><br><span class="line">devtmpfs        3.9G     0  3.9G   0% &#x2F;dev</span><br><span class="line">tmpfs           3.9G   16K  3.9G   1% &#x2F;dev&#x2F;shm</span><br><span class="line">tmpfs           3.9G  258M  3.6G   7% &#x2F;run</span><br><span class="line">tmpfs           3.9G     0  3.9G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup</span><br><span class="line">tmpfs           783M     0  783M   0% &#x2F;run&#x2F;user&#x2F;1004</span><br></pre></td></tr></table></figure><p>（系统启动多少时间，可以看到今天前什么时候重启过）（几个用户在登录）（系统负载，1分钟5分钟15分钟，<em>判断服务器卡不卡</em>）</p><p>top - 21:20:22 up 7 days, 58 min,  1 user,<em>load average: 0.01, 0.03, 0.05</em><br>Tasks:  89 total,   1 running,  88 sleeping,   0 stopped,   0 zombie<br>%Cpu(s):  0.2 us,  0.5 sy,  0.0 ni, 99.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.3 st<br>KiB Mem :  8011076 total,  6377388 free,   229060 used,  1404628 buff/cache<br>KiB Swap:        0 total,        0 free,        0 used.  7265724 avail Mem </p><p>  PID USER      PR  NI    VIRT    RES    SHR S  <em>%CPU %MEM</em>     TIME+ COMMAND<br> 2374 root      20   0  394348  31376   8608 S   0.3  0.4  41:44.99 jdog-kunlunmirr<br>    1 root      20   0  125356   3796   2508 S   0.0  0.0   1:22.32 systemd<br>    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd<br>    3 root      20   0       0      0      0 S   0.0  0.0   0:00.08 ksoftirqd/0<br>    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H<br>    6 root      20   0       0      0      0 S   0.0  0.0   0:02.50 kworker/u4:0  </p><p>系统负载<br>&emsp;&emsp;load average: 0.01, 0.03, 0.05<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;          1min   5min  15min</p><p>&emsp;&emsp;经验值: 10  生产不用超过这个 ，否则认为服务器就是卡<br>&emsp;&emsp;&emsp;&emsp;a.是你的程序有问题 在大量跑计算<br>&emsp;&emsp;&emsp;&emsp;b.是不是被挖矿 yarn redis 最容易被hacker 攻击<br>&emsp;&emsp;&emsp;&emsp;c.硬件问题  内存条 硬盘</p><p>&emsp;&emsp;a，b选项可以看top中%CPU %MEM，哪些进程属于哪个user占用的cpu和内存过高，排查是故意的操作还是程序问题<br>&emsp;&emsp;c选项遇到过硬盘问题导致程序卡主，导致系统负载过高。。正常服务器负载是1,2,3超过5就要观察，超过10就要排查下<br>&emsp;&emsp;c判断硬件问题最简单方法就是重启服务器，如果硬件损坏开机就会有灯闪</p><h4 id="软连接-ln"><a href="#软连接-ln" class="headerlink" title="软连接 ln"></a>软连接 ln</h4><p>软连接就相当于window里的快捷方式,是一个空文件夹</p><p>ln -s hadoop-2.6.0-cdh5.16.2 hadoop<br><em>软连接优点</em>:<br>1.方便版本切换<br>&emsp;&emsp;比如我在shell脚本里写的目录是/home/hadoop/app/hadoop-2.6.0-cdh5.16.2如果我升级hadoop版本,那么我每个shell脚本都需要修改版本非常麻烦<br>若果我用软连接可以直接在shell脚本里写/home/hadoop/app/hadoop 如果hadoop升级了,我只需要先删除hadoop这个软连接,之后重新创建软连接hadoop指向最新的地址就行了不需要挨个修改shell脚本</p><p>2.小盘换大盘<br>&emsp;&emsp;比如目录 /app/log/hadoop-hdfs 是在跟目录下面的,企业中根目录一般设置比较小假设为20G  比如hadoop-hdfs这个文件夹使用了18个G,则占用了根目录很多空间<br>此时我想把数据迁移到大盘/data01下,但是还要通过原来的路径访问(因为这样可以不改变程序代码)此时可以用软连接<br>mv /app/log/hadoop-hdfs  /data01/  ==&gt;结果:/data01/hadoop-hdfs  (数据移动到大盘)<br>ln -s /data01/hadoop-hdfs /app/log/hadoop-hdfs</p><h4 id="yum安装"><a href="#yum安装" class="headerlink" title="yum安装"></a>yum安装</h4><p> yum search httpd<br> yum install httpd</p><p>centos6:<br>service httpd status|start|stop  1个应用httpd</p><p>centos7:<br>service httpd status|start|stop  是向下兼容的也能使用<br>systemctl status|start|stop httpd app2 app3 app4  一次性操作多个应用</p><p>搜索 卸载:<br>[root@hadoop101 ~]# rpm -qa|grep http<br>httpd-2.4.6-90.el7.centos.x86_64<br>httpd-tools-2.4.6-90.el7.centos.x86_64<br>[root@hadoop101 ~]# rpm -e 包名称 –nodeps</p><p>[root@hadoop101 ~]# yum remove httpd-2.4.6-90.el7.centos.x86_64</p><h4 id="进程-端口号"><a href="#进程-端口号" class="headerlink" title="进程 端口号"></a>进程 端口号</h4><p>ps -ef | grep http<br>kill -9 16629<br>kill -9 16630 16631  16632  16633  16634</p><p>根据匹配字段 搜索所有符合的进程 全部杀死<br>但是: 生产慎用 除非你先ps查看 这个关键词搜索的进程 是不是都是你想要杀死的进程<br>保不齐有个其他服务的进程 会造成误杀 生产事故！！！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 ~]# ps -ef|grep http</span><br><span class="line">root     18363     1  0 21:51 ?        00:00:00 &#x2F;usr&#x2F;sbin&#x2F;httpd -DFOREGROUND</span><br><span class="line">apache   18364 18363  0 21:51 ?        00:00:00 &#x2F;usr&#x2F;sbin&#x2F;httpd -DFOREGROUND</span><br><span class="line">apache   18365 18363  0 21:51 ?        00:00:00 &#x2F;usr&#x2F;sbin&#x2F;httpd -DFOREGROUND</span><br><span class="line">apache   18366 18363  0 21:51 ?        00:00:00 &#x2F;usr&#x2F;sbin&#x2F;httpd -DFOREGROUND</span><br><span class="line">apache   18367 18363  0 21:51 ?        00:00:00 &#x2F;usr&#x2F;sbin&#x2F;httpd -DFOREGROUND</span><br><span class="line">apache   18368 18363  0 21:51 ?        00:00:00 &#x2F;usr&#x2F;sbin&#x2F;httpd -DFOREGROUND</span><br><span class="line">root     18387 15881  0 21:51 pts&#x2F;2    00:00:00 grep --color&#x3D;auto http</span><br></pre></td></tr></table></figure><p>上面第二列是进程号 第三列是父进程号  , 可知18363是主进程 </p><p><em>想知道进程占用哪个端口号(netstat -nlp| grep 3306（查看端口启动哪个进程）。netstat -nlp| grep mysql（查看mysql占用哪个端口）)</em>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@ruozedata001 ~]# netstat -nlp| grep 18670</span><br><span class="line">tcp6       0      0 :::80                   :::*                    LISTEN      18670&#x2F;httpd         </span><br><span class="line">[root@ruozedata001 ~]# </span><br><span class="line">[root@ruozedata001 ~]# </span><br><span class="line">[root@ruozedata001 ~]# </span><br><span class="line">[root@ruozedata001 ~]# netstat -nlp| grep 18671</span><br><span class="line">[root@ruozedata001 ~]# netstat -nlp| grep 18672</span><br><span class="line">[root@ruozedata001 ~]# netstat -nlp| grep 18673</span><br><span class="line">[root@ruozedata001 ~]#</span><br></pre></td></tr></table></figure><p>上面可见进程不一定都会起到端口号<br>但是  与其他服务通信 必然需要端口号！！！</p><p>老板: 去打开的应用yyy的网页？你会涉及到哪些Linux命令<br>我知道xxx服务器的ip,之后查询这个yyy对应的端口号:ps -ef|grep yyy ,知道进程号后得到该进程占用的端口号:netstat -nlp|grep pid<br>此时已经得到了端口号之后浏览器里输入<a href="http://ip:端口号">http://ip:端口号</a>   (还需要确保能ping 通 ip还有端口号)</p><p>细节:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@ruozedata001 ~]# netstat -nlp| grep 18670</span><br><span class="line">tcp6       0      0 :::80                   :::*                    LISTEN      18670&#x2F;httpd         </span><br><span class="line">tcp6       0      0 :80                   :::*                    LISTEN      18670&#x2F;httpd         </span><br><span class="line">tcp6       0      0 192.168.0.3:80                   :::*                    LISTEN      18670&#x2F;httpd         </span><br><span class="line">::和0.0.0.0等价于当前机器的ip</span><br><span class="line"></span><br><span class="line">tcp6       0      0 127.0.0.1:80                   :::*                    LISTEN      18670&#x2F;httpd         </span><br><span class="line">tcp6       0      0 localhost:80                   :::*                    LISTEN      18670&#x2F;httpd</span><br></pre></td></tr></table></figure><p>危险: 127.0.0.1和localhost该服务只能自己服务器的里面自己访问自己,外面的服务器访问不了该服务<br>生产中遇到过:服务启动了,防火墙也关了,但是连接不上服务 原因就是是以127.0.0.1的方式启动的,默认配置文件没有修改</p><p>测试服务通不通:           ping ip<br>测试服务器端口能不能通:   telnet ip port</p><p>yum install -y telnet</p><p>学习时：如果都不能通可能防火墙开启。如果是云主机需要开启安全组策略<br>生产中：如果都不能通，直接找linux运维 网络工程师（这个就需要加防火墙策略，防火墙分为硬件或者软件，软件一般便宜一些）</p><p>总结:<br>看到错误 Connection refused</p><ol><li>ping   ip    (<em>失败未必就是不能连接的有些服务器是禁止ping的(防止黑客扫描) 但是做telnet ip port是可以的</em>)</li><li>telnet ip  port  ok</li></ol><p>配置企业级别yum源 取代互联网的repo文件的URL (因为我们做的东西都是内网的是物理隔绝的不会连接互联网,)</p><p>4.下载<br>wget <a href="https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar" target="_blank" rel="noopener">https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar</a><br>curl <a href="https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar" target="_blank" rel="noopener">https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar</a> -O  spark-core_2.12-2.4.5.jar</p><p>5.压缩 解压<br>zip -r xxx.zip xxx/*<br>unzip xxx.zip  解压缩  .zip</p><p>tar -czvf xxxx.tar.gz  xxxx/*<br>tar -zxvf xxxx.tar.gz  解压缩  .tar</p><p>-C 路径 表示解压到路径下</p><p>Examples:<br>  tar -cf archive.tar foo bar  # Create archive.tar from files foo and bar.<br>  tar -tvf archive.tar         # List all files in archive.tar verbosely.<br>  tar -xf archive.tar          # Extract all files from archive.tar.</p><p>tar -xvf  解压缩 .tar.bz  </p><h4 id="如何找到命令-which"><a href="#如何找到命令-which" class="headerlink" title="如何找到命令  which"></a>如何找到命令  which</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 ~]# which ls</span><br><span class="line">alias ls&#x3D;&#39;ls --color&#x3D;auto&#39;</span><br></pre></td></tr></table></figure><p>想要命令快速找到  which xxx 来验证，其实就是提前将命令的目录配置在环境变量$PATH<br>echo $PATH 来查看是否将命令的目录配置上！</p><h4 id="定时"><a href="#定时" class="headerlink" title="定时"></a>定时</h4>]]></content>
      
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux</title>
      <link href="/2015/07/18/linux/linux1/"/>
      <url>/2015/07/18/linux/linux1/</url>
      
        <content type="html"><![CDATA[<p>[root@hadoop102 ~]<br>root : 登录用户时root，root是默认管理员  有最大权限<br>hadoop102 : 指的是机器名<br>~ : 指的是当前该用户的家目录</p><h2 id="命令介绍"><a href="#命令介绍" class="headerlink" title="命令介绍"></a>命令介绍</h2><p>/路径是linux的根路径</p><p>1) pwd  : 查看当前光标所在的目录</p><h4 id="ls命令"><a href="#ls命令" class="headerlink" title="ls命令"></a>ls命令</h4><p>2) ls : 查看<br>&emsp;&emsp;ls -l  显示额外信息(权限 用户用户组  时间  大小)   等价于:<strong>ll</strong><br>&emsp;&emsp;ll -a  也显示隐藏文件夹、文件<br>&emsp;&emsp;&emsp;&emsp;隐藏文件和文件夹都是以‘.’开头，我们可以自己隐藏文件或文件夹<br>&emsp;&emsp;ll  -h 查看 <strong>文件</strong> 的大小<br>&emsp;&emsp;ll -rt :  其中 -r -t是按照时间排序,可以快速找到哪些文件或者文件夹更新了</p><p>3) cd : 切换路径<br>&emsp;&emsp;cd ..  : 返回上一层目录<br>&emsp;&emsp;cd - : 回退到上一次的目录</p><h4 id="家目录"><a href="#家目录" class="headerlink" title="家目录"></a>家目录</h4><p>root是系统管理员用户 家目录是 /root<br>创建的普通用户xx     家目录是 /home/xx </p><p>家目录是 ~ 表示<br>如何进入家目录??<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; ① cd 对应用户家目录<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; ② cd  直接回车<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; ③ cd ~</p><p>4) mkdir : 创建文件夹<br>&emsp;&emsp;需求：创建并联的三个文件夹  mkdir dir1 dir2 dir3<br>&emsp;&emsp;需求：创建串联的三个文件夹  mkdir -p dir4/dir5/dir6<br>5) help : 命令帮助<br>&emsp;&emsp;ls –help<br>6) clear : 清空屏幕 或者 Ctrl+l</p><h4 id="查看文件-文件夹大小"><a href="#查看文件-文件夹大小" class="headerlink" title="查看文件/文件夹大小"></a>查看文件/文件夹大小</h4><p>查看文件大小： ll -h 、du -sh<br>查看文件夹大小:        du -sh</p><h4 id="移动拷贝"><a href="#移动拷贝" class="headerlink" title="移动拷贝"></a>移动拷贝</h4><p>7) mv : 移动<br>&emsp;&emsp;标准写法  : mv dir1 dir0/dir1<br>&emsp;&emsp;不标准写法: mv dir1 dir0<br>8) cp : 拷贝<br>&emsp;&emsp;标准写法  : cp -r dir2 dir0/dir2    //加-r是复制文件夹,如果不是复制文件夹可以不加-r<br>&emsp;&emsp;不标准写法: cp -r dir2 dir0</p><p>&emsp;&emsp;mv是始终一份  速度快<br>&emsp;&emsp;cp是两份 速度慢一点</p><h4 id="创建文件"><a href="#创建文件" class="headerlink" title="创建文件"></a>创建文件</h4><p>9)  touch : 创建空文件<br>10) vi    : 创建文件并编辑<br>&emsp;&emsp; vi 1.log<br>&emsp;&emsp;&emsp;&emsp;默认命令模式 。i建 进入编辑模式 。Esc建 从编辑模式进入命令模式 。Shift+:建从命令行模式进入尾行模式,输入wq退出<br>11) echo : 打印<br>12) &gt; : 创建或者覆盖 (<font color="red"><b>高危命令</b></font>)<br>&emsp;&emsp;&emsp;&emsp;echo “hello” &gt; 3.log<br>&emsp;&emsp;注意:<em>&gt; 左右两面的空格不能丢</em><br>13) &gt;&gt; : 追加<br>&emsp;&emsp;&emsp;&emsp;echo “hello world” &gt;&gt; 3.log</p><h4 id="查看文件内容"><a href="#查看文件内容" class="headerlink" title="查看文件内容"></a>查看文件内容</h4><p>14) cat 查看文件内容,文件内容一次全部显示   ctrl+z中断<br>15) more 文件内容一页页往下翻，按空格往下  无法回退  q退出<br>16）less 文件内容 按↑↓键翻行    q退出  用的少<br>&emsp;&emsp;&emsp;&emsp;cat适合文件内容少的。 文件内容稍微多点的用more<br>17）tail<br>&emsp;&emsp;tail -f  xxx.log  实时监控文件内容，如果文件移除停止监控,再创建xxx.log文件也不会继续监控<br>&emsp;&emsp;tail -F  xxx.log  实时监控文件内容，如果文件移除会继续尝试读取内容不会停止,再创建xxx.log文件后还能继续监控</p><p>需求:实时查看文件内容倒数100行<br>&emsp;&emsp;tail -100f xxx.log   注意:此处只能f不能用F</p><p>需求:文件内容很多,如何搜索error信息</p><p>‘|’:管道符,前面的结果作为后面的输入<br>‘grep’:过滤<br>&emsp;&emsp;cat xxx.log | grep -A 5 ERROR。error后5行信息<br>&emsp;&emsp;cat xxx.log | grep -B 5 ERROR。error前5行信息<br>&emsp;&emsp;cat xxx.log | grep -C 5 ERROR。error前后各5行信息</p><p>但是如果error很多,用cat可能会刷屏,所以优化为: cat xxx.log | grep -C 5 ERROR &gt; 20150718error.log</p><h4 id="window-linux互传文件"><a href="#window-linux互传文件" class="headerlink" title="window,linux互传文件"></a>window,linux互传文件</h4><p>安装工具包 yum install -y lrzsz<br>sz xxx.log是下载 Linux–》window   下载位置查看CRT的配置<br>rz+回车 是上传   window–》Linux</p><h4 id="别名"><a href="#别名" class="headerlink" title="别名"></a>别名</h4><p>18) 别名 alias</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@ruozedata001 log]# alias</span><br><span class="line">alias cp&#x3D;&#39;cp -i&#39;</span><br><span class="line">alias egrep&#x3D;&#39;egrep --color&#x3D;auto&#39;</span><br><span class="line">alias fgrep&#x3D;&#39;fgrep --color&#x3D;auto&#39;</span><br><span class="line">alias grep&#x3D;&#39;grep --color&#x3D;auto&#39;</span><br><span class="line">alias l.&#x3D;&#39;ls -d .* --color&#x3D;auto&#39;</span><br><span class="line">alias ll&#x3D;&#39;ls -l --color&#x3D;auto&#39;</span><br><span class="line">alias ls&#x3D;&#39;ls --color&#x3D;auto&#39;</span><br><span class="line">alias mv&#x3D;&#39;mv -i&#39;</span><br><span class="line">alias rm&#x3D;&#39;rm -i&#39;</span><br><span class="line">alias which&#x3D;&#39;alias | &#x2F;usr&#x2F;bin&#x2F;which --tty-only --read-alias --show-dot --show-tilde&#39;</span><br></pre></td></tr></table></figure><p>上面解释了为什么ls -l可以简写为ll</p><p>&emsp;&emsp;创建别名 : alias jj=’cd /tmp’  (注意中间不要乱用空格) (<strong>只在当前会话生效,想要全局生效需要把命令拷贝到对应用户的配置文件然后生效文件</strong>)</p><h4 id="全局变量"><a href="#全局变量" class="headerlink" title="全局变量"></a>全局变量</h4><p>全局变量(<em>配置完了需要生效配置,并且重新打开CRT窗口</em>)<br>全局：/etc/profile   <strong>所有用户都可以使用</strong><br>个人:                <strong>只能当前用户使用,其他不能使用</strong><br>&emsp;&emsp; ~/.bash_profile<br>&emsp;&emsp; ~/.bashrc    (个人环境变量设置推荐这个文件)</p><p>场景: ssh 远程执行B机器 命令  找不到   java command not found<br>但是直接登录B机器 命令是能找到的,原因:命令的环境变量配置在.bash_profile  是不正确的。应该配置在.bashrc文件里面</p><p><em>生产中新配置的环境变量应该放到PATH前面,如果配置到后面可能会被前面配置的截胡</em></p><p>配置完后一定要<em>生效</em>文件:<br>&emsp;&emsp;source /etc/profile<br>&emsp;&emsp;source ~/.bash_profile<br>&emsp;&emsp;source ~/.bashrc</p><p>检查是否生效：which<br>例子:配置java变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;etc&#x2F;profile添加</span><br><span class="line">#env</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_45</span><br><span class="line">export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH</span><br><span class="line"></span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line"></span><br><span class="line">which java</span><br></pre></td></tr></table></figure><p>CRT窗口是静态窗口,配置生效后可以重新打开个窗口,拿到最新状态</p><h4 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h4><p>19) useradd clouduncle：添加用户clouduncle<br>20) su clouduncle:切换用户clouduncle</p><h4 id="历史命令"><a href="#历史命令" class="headerlink" title="历史命令"></a>历史命令</h4><p>21) history<br>&emsp;自己写的命令不想让别人看到  : history -c (清空history)<br>直连  服务器 history -c可以生效<br>跳板机(vpn)  连接  服务器 history -c可以生效<br>堡垒机 敲一个命令都记录在堡垒机系统里,一般都有可视化web界面,能搜索谁做了什么命令  history -c就不会有效果</p><h4 id="高危命令"><a href="#高危命令" class="headerlink" title="高危命令"></a>高危命令</h4><p>&emsp;&emsp; <em>千万不要做 rm -rf /</em>  运维可以限制这个命令失效<br>&emsp;&emsp;删除文件: rm 11.log   会询问是否删除<br>&emsp;&emsp;不询问直接删除文件: rm -f 11.log<br>&emsp;&emsp;删除文件夹: rm -r dir1<br>&emsp;&emsp;不询问直接删除文件夹: rm -rf dir1</p><p>场景: <em>注意</em><br>&emsp;&emsp;脚本里<br>&emsp;&emsp;LOG_PATH=/xxx/yyy<br>&emsp;&emsp;&emsp;&emsp;业务逻辑判断去赋值,如果漏掉了一种没有赋值那么LOG_PATH为空<br>&emsp;&emsp;rm -rf ${LOG_PATH} /*  ==&gt; rm -rf /*</p><p>怎么避免?<br>每次执行这个命令之前 , 先判断${LOG_PATH}是否存在然后才能执行</p><p>发生了怎么办？<br>如果不小心执行了这个操作且没有备份，则马上停止所有服务不要往硬盘上再写数据了，让运维去拿着硬盘去维修公司恢复数据。<br>最好是运维做出这种命令限制</p><h4 id="用户和用户组（一般都是由运维操作，除非平台运维都由自己团队接过来）"><a href="#用户和用户组（一般都是由运维操作，除非平台运维都由自己团队接过来）" class="headerlink" title="用户和用户组（一般都是由运维操作，除非平台运维都由自己团队接过来）"></a>用户和用户组（一般都是由运维操作，除非平台运维都由自己团队接过来）</h4><h5 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h5><p>1）创建普通用户clouduncle: useradd clouduncle<br>&emsp;&emsp;同时也会创建clouduncle的用户组,设置clouduncle用户的组为clouduncle,且把clouduncle用户组设置为主组同时也创建家目录 /home/clouduncle</p><p>&emsp;&emsp;用户存储信息一般记录在:    /etc/passwd<br>&emsp;&emsp;用户组存储信息一般记录在:  /etc/group</p><p>2）查看用户clouduncle信息：id clouduncle</p><p>3) 删除用户clouduncle：userdel clouduncle<br>删除用户后, /home/clouduncle文件夹还存在,之后手动删除该文件夹下的所有文件包括隐藏文件模拟全局变量丢失。重新创建clouduncle用户<br>出现问题:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 home]# su clouduncle</span><br><span class="line">bash-4.1$ </span><br><span class="line"></span><br><span class="line">[root@hadoop102 clouduncle]# ll -a &#x2F;etc&#x2F;skel&#x2F;.*</span><br><span class="line">总用量 36</span><br><span class="line">drwxr-xr-x.   4 root root  4096 2月   8 2018 .</span><br><span class="line">drwxr-xr-x. 107 root root 12288 5月  25 21:03 ..</span><br><span class="line">-rw-r--r--.   1 root root    18 5月  11 2016 .bash_logout</span><br><span class="line">-rw-r--r--.   1 root root   176 5月  11 2016 .bash_profile</span><br><span class="line">-rw-r--r--.   1 root root   124 5月  11 2016 .bashrc</span><br><span class="line">drwxr-xr-x.   2 root root  4096 11月 12 2010 .gnome2</span><br><span class="line">drwxr-xr-x.   4 root root  4096 2月   8 2018 .mozilla</span><br></pre></td></tr></table></figure><p>出现上述问题原因是当前用户的家目录里面缺少了全局变量信息,此时如下操作:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 clouduncle]# cp &#x2F;etc&#x2F;skel&#x2F;.* .&#x2F;</span><br></pre></td></tr></table></figure><p>4)切换用户: su<br>&emsp;&emsp;推荐: su - clouduncle   (其中’-‘代表该用户切换到家目录,且执行环境变量文件)</p><p>5)普通用户临时使用root的最大权限 : sudo<br>&emsp;&emsp;root用户下<br>&emsp;&emsp;&emsp;&emsp;vi /etc/sudoers<br>&emsp;&emsp;&emsp;&emsp;添加 : clouduncle ALL=(root)       NOPASSWD:ALL</p><p><em>生产中可以要求运维给自己linux用户加一个sudo的权限</em></p><h6 id="设置密码"><a href="#设置密码" class="headerlink" title="设置密码"></a>设置密码</h6><p>1)修改用户密码: passwd<br>&emsp;&emsp;passwd+回车 修改当前光标所属用户密码<br>&emsp;&emsp;passwd clouduncle 修改clouduncle的密码</p><p>2)./etc/passwd文件<br>下面两种情况切换用户都会失败<br>&emsp;&emsp;clouduncle:x:1004:1005::/home/clouduncle:/sbin/nologin  提示<br>&emsp;&emsp;clouduncle:x:1004:1005::/home/clouduncle:/usr/bin/false 没提示</p><p>CDH平台很多用户如 hdfs yarn hive<br>su - yarn是不成功的,原因是yarn的/sbin/nologin /usr/bin/false 需要改成 /bin/bash</p><h5 id="用户组"><a href="#用户组" class="headerlink" title="用户组"></a>用户组</h5><p>1)创建组bigdata : groupadd bigdata<br>2)查看组: cat /etc/group|grep bigdata<br>3)将用户分配到bigdata组: (usermod –help查询方法)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 clouduncle]# usermod -a -G bigdata clouduncle</span><br><span class="line">[root@hadoop102 clouduncle]# id clouduncle</span><br><span class="line"> uid&#x3D;501(clouduncle) gid&#x3D;501(clouduncle) 组&#x3D;501(clouduncle),502(bigdata)</span><br></pre></td></tr></table></figure><p>4)设置bigdata为用户clouduncle主组(gid): usermod -g bigdata clouduncle</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 clouduncle]# usermod -g bigdata clouduncle</span><br><span class="line">[root@hadoop102 clouduncle]# id clouduncle</span><br><span class="line">uid&#x3D;501(clouduncle) gid&#x3D;502(bigdata) 组&#x3D;502(bigdata)</span><br><span class="line">[root@hadoop102 clouduncle]#  usermod -a -G clouduncle clouduncle</span><br><span class="line">[root@hadoop102 clouduncle]# id clouduncle</span><br><span class="line">uid&#x3D;501(clouduncle) gid&#x3D;502(bigdata) 组&#x3D;502(bigdata),501(clouduncle)</span><br></pre></td></tr></table></figure><h4 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h4><p>-rw-r–r– 1 root root  9 Apr 18 20:50 22.log<br>drwxr-xr-x 2 root root  6 Apr 15 22:12 dir3</p><p>&emsp;&emsp;第一个字母：d文件夹 -文件  l连接</p><p>&emsp;&emsp;后面9个字母,3个字母为一组：<br>r：read  读权限 代表数字是4<br>w：write 写权限 代表数字是2<br>x：      执行   代表数字是1<br>-：      没权限 代表数字是0  占位 </p><p>7=4 2 1<br>5=4 1<br>6=4 2</p><p>&emsp;&emsp;rw- 第一组 6  代表文件或文件夹的所属<em>用户</em>，读写权限<br>&emsp;&emsp;r– 第二组 4  代表文件或文件夹的所属<em>用户组</em>，读权限<br>&emsp;&emsp;r– 第三组 4  代表<em>其他用户组的用户</em>对这个文件或文件夹，读权限</p><p>例子: rw-r- -r- -    root root     22.log<br>&emsp;&emsp;可以看到22.log 属于root用户 属于root用户组<br>&emsp;&emsp;root用户看前三个对22.log有读和写的权限。root用户组看中间对22.log有读权限。其他用户组的用户看后三个，对22.log有读权限</p><p>关于权限：<br>&emsp;&emsp;chmod -R 777 文件或文件夹  (777分别对应所属用户、所属用户组、其他用户组的用户  所拥有的权限)(7=4+2+1)<br>&emsp;&emsp;chown -R 用户:用户组  文件或文件夹<br>其中-R ： 以递归方式更改所有的文件及子目录<br><em>chmod是修改文件或文件夹对不同用户不同用户组的权限</em><br><em>chown是给文件夹或文件修改所属用户和用户组</em></p><p>案例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 tmp]# vi clouduncle.log</span><br><span class="line">www.baidu.com</span><br><span class="line"></span><br><span class="line">[clouduncle@hadoop102 tmp]$ cat  clouduncle.log </span><br><span class="line">www.baidu.com</span><br><span class="line"></span><br><span class="line">收回其他组的r权限 </span><br><span class="line">[root@hadoop102 tmp]# chmod 640 clouduncle.log</span><br><span class="line">[clouduncle@hadoop102 tmp]$ cat  clouduncle.log </span><br><span class="line">cat: clouduncle.log: Permission denied</span><br></pre></td></tr></table></figure><h4 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h4><p>场景：接手大数据平台，服务器登录，大数据组件安装目录在哪？<br>&emsp;&emsp;  find / -name ‘*hadoop*‘ (/表示从根目录开始,*是通配符)  如果生产服务器挂10个盘,那么每个盘都要扫描<br>&emsp;&emsp;  find /opt/module -name  ‘*hadoop’</p><p>补充:<br>history 命令<br>ps -ef 查看进程</p><h4 id="vi"><a href="#vi" class="headerlink" title="vi"></a>vi</h4><p>&emsp;&emsp;默认命令模式 。i建 进入编辑模式 。Esc建 从编辑模式进入命令模式 。Shift+:建从命令行模式进入尾行模式,输入wq退出，wq!强制保存退出，q!强制退出不保存<br>正常编辑一个文件，要正常退出 wq<br>&emsp;&emsp;如果编辑的时候进程被杀死没正常退出:<br>&emsp;&emsp;-rw-r–r–   1 root  root       16 Apr 19 21:26 2.log<br>&emsp;&emsp;-rw-r–r–   1 root  root    12288 Apr 19 21:31 .2.log.swp<br>&emsp;&emsp;之后再次编辑会无法编辑出现found a swap file by the name “.2.log.swp”<br>&emsp;&emsp;解决方法:删除”.2.log.swp”文件,这是个隐藏文件需要ll -a才能看到  </p><p>&emsp;&emsp;<em>注意粘贴的坑,如果在命令模式的时候直接粘贴会出现第一行内容丢失 不完整,所以必须先进入编辑模式才能粘贴</em></p><p>如果想要搜索文件XXX内容可以 尾行模式输入 /XXX<br>如果想要显示行号,尾行模式输入  set nu   设置行号   , set nonu 取消行号<br>如果想要知道光标所在的行,尾行模式输入  f</p><p>命令模式常用快捷方式<br>dd  删除光标当前行<br>dG  删除光标当前及以下的所有行<br>ndd 删除光标当前行及以下n行</p><p>gg 光标跳转到第一行第一个字母<br>G  光标跳转到最后一行第一个字母<br>shift + $ 行尾</p><p>场景：清空这个文件内容，从另外一个文件内容 拷贝过来<br>gg–》dG   –》 <em>i</em>  –&gt;鼠标右键单击 粘贴上</p><p>清空补充：<br>cat /dev/null &gt; 1.log<br>echo  “” &gt; 2.log<br>true &gt; 1.log 也是清空文件内容 0字节</p><p>[root@ruozedata001 ~]# ll<br>total 16<br>-rw-r–r– 1 root  root     0 Apr 19 21:58 1.log<br>-rw-r–r– 1 root  root     1 Apr 19 21:58 2.log</p><p>可以看到第一种方式清空是0字节，第二种方式清空还有一个字节<em>其实并没有真正清空还有个空白行</em></p><p>场景:<br>shell脚本，对数据文件清空操作，根据字节大小判断是否清空完成<br>echo  “” &gt; 2.log<br>if filezie &gt; 0 then<br>   业务不操作</p><p>else<br>    2.log 灌业务数据</p><p>上面清空操作是错误文件自己数不会为0，永远不会进入业务操作</p><h2 id="linux两个机制"><a href="#linux两个机制" class="headerlink" title="linux两个机制"></a>linux两个机制</h2><p>&emsp;&emsp; oom-killer机制：当linux服务器某个进程使用内存超标 Linux机器为了保护自己，会主动杀死进程，释放内存。这个就是本来我的进程好好的，过了一夜莫名其妙的挂了，可能就是触发了这个机制。<br>&emsp;&emsp; /tmp目录 30天自动删除机制</p><h4 id="结束了"><a href="#结束了" class="headerlink" title="结束了"></a>结束了</h4>]]></content>
      
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title></title>
      <link href="/404.html"/>
      <url>/404.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>About</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>search</title>
      <link href="/search/index.html"/>
      <url>/search/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>Archives</title>
      <link href="/archive/index.html"/>
      <url>/archive/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
