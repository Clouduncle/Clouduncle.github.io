
<!DOCTYPE html>
<html lang="zh-CN">


<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <meta name="theme-color" content="#202020"/>
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
  
  
    <meta name="keywords" content="Hive," />
  

  
    <meta name="description" content="一起成长" />
  
  
  <link rel="icon" type="image/x-icon" href="/logo.png">
  <title>Hive [ 小彩鸟 ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css">
    
      <link rel="stylesheet" href="/css/xoxo.css">
    
  
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <div class="nav-container">
    <nav class="home-menu pure-menu pure-menu-horizontal">
  <a class="pure-menu-heading" href="/">
    <img class="avatar" src="/images/logo.png">
    <span class="title">小彩鸟</span>
  </a>

  <ul class="pure-menu-list clearfix">
      
          
            <li class="pure-menu-item"><a href="/" class="pure-menu-link">首页</a></li>
          
      
          
            <li class="pure-menu-item"><a href="/archives" class="pure-menu-link">归档</a></li>
          
      
          
            <li class="pure-menu-item"><a href="/tags" class="pure-menu-link">标签</a></li>
          
      
          
            <li class="pure-menu-item"><a href="/search" class="pure-menu-link">搜索</a></li>
          
      
  </ul>
   
</nav>
  </div>

  <div class="container" id="content-outer">
    <div class="inner" id="content-inner">
      <div class="post-container">
  <article class="post" id="post">
    <header class="post-header text-center">
      <h1 class="title">
        Hive
      </h1>
      <span>
        
        <time class="time" datetime="2016-07-10T04:00:00.000Z">
        2016-07-10
      </time>
        
      </span>
      <span class="slash">/</span>
      <span class="post-meta">
      <span class="post-tags">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>
      </span>
    </span>
      <span class="slash">/</span>
      <span class="read">
      <span id="busuanzi_value_page_pv"></span> 点击
    </span>
      <span class="slash">/</span>
    </header>

    <div class="post-content">
      <h2 id="Hive介绍"><a href="#Hive介绍" class="headerlink" title="Hive介绍"></a>Hive介绍</h2><p>&emsp;&emsp;Hive是基于Hadoop的一个数据仓库工具，可以将结构化数据文件映射为一张表，并提供类SQL查询功能，Hive的sql叫HQL。<em>Hive职责:将SQL转换为对应引擎的作业</em>，Hive的数据存放在HDFS（源数据） + MySQL（元数据），想使用SQL进行查询Hadoop上的数据，源数据和元数据都是必不可少的。Hive就是个客户端而已,并不存在集群的概念，当然hive也可以部署多个，但是多个hive间是没有关系的。<br>&emsp;&emsp;Hive的优势在于处理大数据,对于处理小数据没有优势，因为Hive的的适用场景是离线/批计算,不关注延时性</p>
<h2 id="Hive架构"><a href="#Hive架构" class="headerlink" title="Hive架构"></a>Hive架构</h2><p><img src="/img/Hive/hive%E6%9E%B6%E6%9E%84.png" alt="Hive架构图"></p>
<h3 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h3><p>&emsp;&emsp;Metastore：元数据包括报名，表所属数据库，表的拥有者，列/分区字段，表的类型（是否是外部表），表的数据所在的目录。默认存储在自带的derby数据库中，为了能多人访问使用Mysql存储元数据。注意和源数据（HDFS存的文本文件）区别。<br>&emsp;&emsp;MetaStore是非常重要的,一旦这个挂了,HDFS源数据的元数据就没有了,所以要有HA的<br>&emsp;&emsp;MetaStore是一个通用的组件:像SparkSQL/Flink/Impala/Presto,也是能访问Hive里面创建的表的,前提是这些框架能访问到hive的元数据<br>mysql中的元数据表有30多种,如:  DBS:存储数据库相关信息  TBLS:存储表的相关信息,包括表名和表的类型  COLUMNS_V2:字段表,保存表的字段名称,字段类型,描述,字段在表中的编号也就是列的位置 </p>
<h3 id="用户接口"><a href="#用户接口" class="headerlink" title="用户接口"></a>用户接口</h3><p>&emsp;&emsp;Client(就是hive的操作页面)包括：CLI就是命令行,JDBC(java访问hive)</p>
<h3 id="SQL-Parser-解析器"><a href="#SQL-Parser-解析器" class="headerlink" title="SQL Parser(解析器)"></a>SQL Parser(解析器)</h3><p>&emsp;&emsp;将sql字符串转换成抽象语法树AST,对AST进行语法分析,比如表是否存在,字段是否存在,sql语义是否有误</p>
<h3 id="Physical-Plan-编译器"><a href="#Physical-Plan-编译器" class="headerlink" title="Physical Plan(编译器)"></a>Physical Plan(编译器)</h3><p>&emsp;&emsp;将AST编译生成逻辑执行计划</p>
<h3 id="Query-Optimizer-优化器"><a href="#Query-Optimizer-优化器" class="headerlink" title="Query Optimizer(优化器)"></a>Query Optimizer(优化器)</h3><p>&emsp;&emsp;对逻辑执行计划进行优化</p>
<h3 id="Execution-执行器"><a href="#Execution-执行器" class="headerlink" title="Execution(执行器)"></a>Execution(执行器)</h3><p>&emsp;&emsp;把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/TEZ/Spark （底层引擎有 : MR,Tez,Spark）</p>
<h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p>&emsp;&emsp;HDFS用于存储数据</p>
<h2 id="Hive和数据库比较"><a href="#Hive和数据库比较" class="headerlink" title="Hive和数据库比较"></a>Hive和数据库比较</h2><p>&emsp;&emsp;hive数据是存储在hdfs上的，而数据库则将数据保存在本地文件系统中<br>&emsp;&emsp;hive更多的是面对分析场景数据不会修改数据，mysql面对的是业务场景需要经常修改数据<br>&emsp;&emsp;hive查询延迟高因为没有所以需要全表扫描而且如果底层引擎是MR那么MR本身延迟就很高，因为每个maptask，reducetask都是启动进程，mysql因为有索引所以查询延迟低（前提是数据规模较小，如果超出一定规模hive的并行计算显然能体现出优势）<br>&emsp;&emsp;hive建立在集群上可以利用mapreduce的并行计算也可以很好地支持扩展（可扩展性），因此可以支持很大规模数据（数据规模）。而数据库可以支持的数据规模较小（目前hadoop集群最大规模是4000台左右，而数据库最大规模是100台左右）</p>
<br/>

<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">下载：http:&#x2F;&#x2F;archive.cloudera.com&#x2F;cdh5&#x2F;cdh&#x2F;5&#x2F;</span><br><span class="line">		在生产上对应的软件版本一定要控制好</span><br><span class="line">			版本选择的基本原则：尾巴一样(版本号)： cdh5.16.2</span><br><span class="line">			Hadoop&#x2F;Hive&#x2F;Sqoop&#x2F;HBase&#x2F;Oozie...</span><br><span class="line">			Spark例外</span><br><span class="line">		所以Hive的版本：hive-1.1.0-cdh5.16.2</span><br><span class="line">		hive-1.1.0-cdh5.16.2-src.tar.gz  源码</span><br><span class="line">		hive-1.1.0-cdh5.16.2.tar.gz  安装包</span><br><span class="line">		wget http:&#x2F;&#x2F;archive.cloudera.com&#x2F;cdh5&#x2F;cdh&#x2F;5&#x2F;hive-1.1.0-cdh5.16.2.tar.gz</span><br><span class="line"></span><br><span class="line">解压：</span><br><span class="line"></span><br><span class="line">tar -zxvf hive-1.1.0-cdh5.16.2.tar.gz -C ~&#x2F;app&#x2F;	</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">配置文件：</span><br><span class="line">		conf Hive相关的配置文件</span><br><span class="line">		bin  Hive相关的脚本</span><br><span class="line">	</span><br><span class="line">添加Hive的bin到环境变量	</span><br><span class="line">		export HIVE_HOME&#x3D;&#x2F;home&#x2F;hadoop&#x2F;app&#x2F;hive-1.1.0-cdh5.16.2</span><br><span class="line">		export PATH&#x3D;$HIVE_HOME&#x2F;bin:$PATH</span><br><span class="line">		注意：改完一定要先source下，或者打开一个新的窗口</span><br><span class="line"></span><br><span class="line">修改配置文件</span><br><span class="line">		Hive的元数据是在MySQL里面的</span><br><span class="line">		如果要访问MySQL的话，需要如下几个参数</span><br><span class="line">			driver、url、user、password</span><br><span class="line">		还需要一个MySQL的驱动类</span><br><span class="line">			***：不建议使用MySQL8的驱动</span><br><span class="line">			需要把MySQL的驱动拷贝到$HIVE_HOME&#x2F;lib			</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Hive相关的配置参数均来自：	</span><br><span class="line">https:&#x2F;&#x2F;cwiki.apache.org&#x2F;confluence&#x2F;display&#x2F;Hive&#x2F;Configuration+Properties</span><br><span class="line"></span><br><span class="line">hive-env.sh</span><br><span class="line"></span><br><span class="line">	</span><br><span class="line">HADOOP_HOME (如果环境变量里有不配置也可以)</span><br><span class="line">export HADOOP_HEAPSIZE&#x3D;1024(需要修改)</span><br><span class="line"></span><br><span class="line">	</span><br><span class="line">特别说明</span><br><span class="line">使用Hive时一定要确保Hadoop环境是OK(包括hdfs的nn处于安全模式也会出问题的)</span><br></pre></td></tr></table></figure>
<h2 id="Hive配置参数"><a href="#Hive配置参数" class="headerlink" title="Hive配置参数"></a>Hive配置参数</h2><h3 id="显示数据库和表头"><a href="#显示数据库和表头" class="headerlink" title="显示数据库和表头"></a>显示数据库和表头</h3><p>hive-site.xml 里</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;!-- 显示所在数据库 --&gt;</span><br><span class="line">    &lt;name&gt;hive.cli.print.header&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;!-- 打印表头信息 --&gt;</span><br><span class="line">    &lt;name&gt;hive.cli.print.current.db&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure>

<h3 id="hive数据库存储路径"><a href="#hive数据库存储路径" class="headerlink" title="hive数据库存储路径"></a>hive数据库存储路径</h3><p>hive创建数据库存放在HDFS的什么位置呢？<br>规则：${hive.metastore.warehouse.dir}/数据库的名称.db<br>hive-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.metastore.warehouse.dir  默认值:&#x2F;user&#x2F;hive&#x2F;warehouse</span><br></pre></td></tr></table></figure>
<h3 id="Hive-log存储路径"><a href="#Hive-log存储路径" class="headerlink" title="Hive log存储路径"></a>Hive log存储路径</h3><p>Hive执行sql,控制台能看到的信息是有限的,所以需要看具体日志信息    </p>
<p>Hive运行时的日志信息在哪里？<br>Hive的log默认存放在/tmp/hadoop001(当前用户名)/hive.log目录下<br>在hive-log4j.properties文件中修改log存放位置 如下:<br>hive.log.dir= /opt/module/hive/logs    (自己定义)</p>
<h3 id="元数据存储到mysql"><a href="#元数据存储到mysql" class="headerlink" title="元数据存储到mysql"></a>元数据存储到mysql</h3><p>hive-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">	  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;&#x2F;name&gt;</span><br><span class="line">	  &lt;value&gt;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;my_hive?createDatabaseIfNotExist&#x3D;true&lt;&#x2F;value&gt;</span><br><span class="line">	&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">	  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;&#x2F;name&gt;</span><br><span class="line">	  &lt;value&gt;com.mysql.jdbc.Driver&lt;&#x2F;value&gt;</span><br><span class="line">	&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">	  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;&#x2F;name&gt;</span><br><span class="line">	  &lt;value&gt;root&lt;&#x2F;value&gt;</span><br><span class="line">	&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">	  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;&#x2F;name&gt;</span><br><span class="line">	  &lt;value&gt;root&lt;&#x2F;value&gt;</span><br><span class="line">	&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="Hive里面涉及到参数的问题如何设置呢？"><a href="#Hive里面涉及到参数的问题如何设置呢？" class="headerlink" title="Hive里面涉及到参数的问题如何设置呢？"></a>Hive里面涉及到参数的问题如何设置呢？</h3><p>1) hive-site.xml  全局配置<br>2) set hive.cli.print.current.db=true;  局部设置<em>仅对当前session有效</em><br>&emsp;&emsp;set key; 显示key的值<br>&emsp;&emsp;set key=value; 设置key的值为value<br>如:<br>&emsp;&emsp;set hive.cli.print.current.db=true;<br>&emsp;&emsp;set hive.cli.print.header=true;</p>
<p>为什么不全都配置到全局的里面去呢？<br>&emsp;&emsp;<em>调优是针对作业的，不一定是针对全局的</em><br>&emsp;&emsp;set key=value;  //设置参数<br>&emsp;&emsp;sql…<br>&emsp;&emsp;set key=原值;   //还原参数</p>
<p>${java.io.tmpdir}: /tmp<br>${user.name}     : hadoop (用户名)<br>${java.io.tmpdir}/${user.name} : /tmp/hadoop/hive.log (生产上可以改)</p>
<h2 id="Hive中的数据类型"><a href="#Hive中的数据类型" class="headerlink" title="Hive中的数据类型"></a>Hive中的数据类型</h2><p>数值类型  ：int/float/double/bigint/decimal/boolean<br>字符串类型：string</p>
<p>生产上时间和日期都是用的字符串类型</p>
<h2 id="Hive基本命令"><a href="#Hive基本命令" class="headerlink" title="Hive基本命令"></a>Hive基本命令</h2><p>交互式命令行: 直接在linux控制台上执行即可<br>    hive -e “select * from student”<br>    hive -f 指定sql文件</p>
<p>shell脚本：<br>    hive -e “select * from student day=${day}”<br>    hive -f 指定sql文件   </p>
<h3 id="DDL-Data-Definition-Language"><a href="#DDL-Data-Definition-Language" class="headerlink" title="DDL(Data Definition Language)"></a>DDL(Data Definition Language)</h3><h4 id="库"><a href="#库" class="headerlink" title="库"></a>库</h4><h5 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name  避免要创建的数据库已经存在错误，增加if not exists判断</span><br><span class="line">[COMMENT database_comment]</span><br><span class="line">[LOCATION hdfs_path]   指定数据库在HDFS上存放的位置</span><br><span class="line">[MANAGEDLOCATION hdfs_path]</span><br><span class="line">[WITH DBPROPERTIES (property_name&#x3D;property_value, ...)];</span><br><span class="line"></span><br><span class="line">[]：表示可有可无</span><br><span class="line">(A|B):里面A和B可以任选其中一个    </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&gt;</span><br><span class="line">create database if not exists db_hive;</span><br><span class="line">create database if not exists db_hive2 location &#39;&#x2F;hive&#x2F;directory&#39;;</span><br></pre></td></tr></table></figure>
<p>hive不管是db,table,分区对应的都是hdfs上的文件夹<br>类似于<br>    【db文件夹/表文件夹/文件】<br>    【db文件夹/表文件夹/分区文件夹(1..n)/文件】</p>
<h5 id="查询数据库"><a href="#查询数据库" class="headerlink" title="查询数据库"></a>查询数据库</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">show databases;</span><br><span class="line">show databases like &#39;db_hive*&#39;;</span><br></pre></td></tr></table></figure>

<h5 id="显示数据库信息"><a href="#显示数据库信息" class="headerlink" title="显示数据库信息"></a>显示数据库信息</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc database db_hive;</span><br></pre></td></tr></table></figure>

<h5 id="使用数据库"><a href="#使用数据库" class="headerlink" title="使用数据库"></a>使用数据库</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use hive;</span><br></pre></td></tr></table></figure>

<h5 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">如果删除的数据库不存在，最好采用 if exists判断数据库是否存在</span><br><span class="line">hive&gt; drop database if exists db_hive2;</span><br><span class="line">如果数据库不为空，可以采用cascade命令，强制删除</span><br><span class="line">hive&gt; drop database db_hive cascade;</span><br><span class="line"></span><br><span class="line">其实生产中都是创建数据库,修改&#x2F;删除(级联删除) 几乎是用不上的</span><br></pre></td></tr></table></figure>
<h4 id="表"><a href="#表" class="headerlink" title="表"></a>表</h4><h5 id="显示表"><a href="#显示表" class="headerlink" title="显示表"></a>显示表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show tables &#39;*emp*&#39;</span><br></pre></td></tr></table></figure>

<h5 id="查看表结构命令"><a href="#查看表结构命令" class="headerlink" title="查看表结构命令"></a><em>查看表结构命令</em></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">*desc formatted student;*</span><br><span class="line"></span><br><span class="line">能查看表路径,表的类型,源数据中列之间的分隔符</span><br></pre></td></tr></table></figure>

<h5 id="查看建表语句"><a href="#查看建表语句" class="headerlink" title="查看建表语句"></a>查看建表语句</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show create table student;</span><br></pre></td></tr></table></figure>

<h5 id="查看表分区"><a href="#查看表分区" class="headerlink" title="查看表分区"></a>查看表分区</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show partitions student;</span><br></pre></td></tr></table></figure>

<h5 id="外部表和内部表"><a href="#外部表和内部表" class="headerlink" title="外部表和内部表"></a>外部表和内部表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">EXTERNAL：外部表</span><br><span class="line">	元数据被删除,HDFS数据依然存在</span><br><span class="line">	</span><br><span class="line">MANAGED：内部表</span><br><span class="line">	HDFS的数据被清空,元数据也会被清空</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">生产中一般都是采用外部表的，好处就是如果误操作了把表删除了，但是数据还是在的，此时重新创建这个表又能查询了，因为重新创建这个表相当于又将元数据添加回来了，自然元数据和源数据就能对应上了</span><br></pre></td></tr></table></figure>

<h5 id="创建普通表"><a href="#创建普通表" class="headerlink" title="创建普通表"></a>创建普通表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">create external table bigdata_emp(</span><br><span class="line">    empno int,</span><br><span class="line">    ename string,</span><br><span class="line">    job string,</span><br><span class="line">    mgr int,</span><br><span class="line">    hiredate string,</span><br><span class="line">    sal double,</span><br><span class="line">    comm double,</span><br><span class="line">    deptno int</span><br><span class="line">) </span><br><span class="line">row format delimited fields terminated by &#39;\t&#39;</span><br><span class="line">location &#39;&#x2F;hive&#x2F;external&#x2F;emp&#x2F;&#39;</span><br><span class="line"></span><br><span class="line">row format delimited fields terminated BY &#39;\t&#39;  指定了列与列的分隔符为&#39;\t&#39;</span><br><span class="line"></span><br><span class="line">或者:</span><br><span class="line">create table emp2 like bigdata_emp;  创建和bigdata_emp一样表结构的表,但是不会复制数据</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line">create table emp3 as select * from bigdata_emp; 创建和bigdata_emp一样表结构的表,而且也会复制进去数据</span><br></pre></td></tr></table></figure>
<p>表在HDFS上的目录：<br>${数据库的目录}/表名/<br>有location那么就是location的文件夹位置:/hive/external/emp/(具体数据文件)</p>
<h5 id="创建分区表"><a href="#创建分区表" class="headerlink" title="创建分区表"></a>创建分区表</h5><p>分区意义:减少全表扫描的可能性,降低磁盘io,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">create table emp2(</span><br><span class="line">    empno int,</span><br><span class="line">    ename string,</span><br><span class="line">    job string,</span><br><span class="line">    mgr int,</span><br><span class="line">    hiredate string,</span><br><span class="line">    sal double,</span><br><span class="line">    comm double</span><br><span class="line">) </span><br><span class="line">PARTITIONED BY (day string)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">也可以用多级分区,如:</span><br><span class="line">create table emp2(</span><br><span class="line">    empno int,</span><br><span class="line">    ename string,</span><br><span class="line">    job string,</span><br><span class="line">    mgr int,</span><br><span class="line">    hiredate string,</span><br><span class="line">    sal double,</span><br><span class="line">    comm double</span><br><span class="line">) </span><br><span class="line">PARTITIONED BY (day string,hour string)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39;</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<p>表在HDFS上的目录(比如按天分区)：<br>${数据库的目录}/表名/day=20161211/<br>${数据库的目录}/表名/day=20161212/</p>
<p>Hive的分区其实对应的还是Hdfs上的文件夹<br>元数据里面也有一张对应的表存放分区信息的</p>
<h5 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE bigdata_emp RENAME TO emp2_new;</span><br></pre></td></tr></table></figure>

<h5 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">drop table if exists student;</span><br><span class="line"></span><br><span class="line">DROP和TRUNCATE的区别?</span><br><span class="line">TRUNCATE仅删除表中数据，保留表结构。Truncate只能删除管理表数据，不能删除外部表中数据</span><br></pre></td></tr></table></figure>


<p>Hive加载数据在生产上使用：</p>
<p>1) load data<br>2) insert (不是values)</p>
<h3 id="DML-Data-Definition-Language"><a href="#DML-Data-Definition-Language" class="headerlink" title="DML(Data Definition Language)"></a>DML(Data Definition Language)</h3><h5 id="load加载数据"><a href="#load加载数据" class="headerlink" title="load加载数据"></a>load加载数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [LOCAL] INPATH &#39;filepath&#39; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1&#x3D;val1, partcol2&#x3D;val2 ...)]</span><br><span class="line">LOCAL: 本地，你执行hive命令那个机器	</span><br><span class="line">无LOCAL：HDFS路径</span><br><span class="line">OVERWRITE：覆盖原先数据</span><br><span class="line">无OVERWRITE：在原先数据上追加</span><br><span class="line"></span><br><span class="line">例子：</span><br><span class="line">添加普通表</span><br><span class="line">load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;data&#x2F;emp.txt&#39; overwrite into table bigdata_emp;</span><br><span class="line">添加分区表</span><br><span class="line">load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;data&#x2F;emp.txt&#39; overwrite into table emp2 partition(day&#x3D;&quot;20220808&quot;);</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line">hadoop fs -put &#x2F;opt&#x2F;module&#x2F;data&#x2F;emp.txt &#x2F;hive&#x2F;external&#x2F;emp&#x2F;</span><br><span class="line"></span><br><span class="line">这两种方法都能将数据放入对应的hive表中</span><br><span class="line">但是要注意hadoop fs -put这种方法,对分区表是不可以的比如:hadoop fs -put &#x2F;opt&#x2F;module&#x2F;data&#x2F;emp.txt &#x2F;hive&#x2F;external&#x2F;emp&#x2F;day&#x3D;20200809&#x2F;  此时查询select * from emp2 where day&#x3D;&#39;20200809&#39;</span><br><span class="line">此时虽然HDFS上的目录&#x2F;hive&#x2F;external&#x2F;emp&#x2F;day&#x3D;20200809&#x2F;是有数据的,但是元数据表中partition_key_values(记录表的分区信息)并没有最新分区20200809的信息,也就是hive metastore并没有感知这个分区的变化</span><br><span class="line">所以可以通过msck repair table emp2 ;   这样元数据信息里就有了20200809  同样也就能查询了</span><br></pre></td></tr></table></figure>

<h5 id="insert加载数据"><a href="#insert加载数据" class="headerlink" title="insert加载数据"></a>insert加载数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">静态分区:</span><br><span class="line">insert into table emp2 partition(day&#x3D;&#39;20200810&#39;) select empno,ename,job,mgr,hiredate,sal,comm,deptno from bigdata_emp;</span><br><span class="line">动态分区: 需要设置非严格模式。插入时候不需要写具体分区,只需要写入分区字段就好。select里面的最后字段作为动态分区依据</span><br><span class="line">insert into table emp2 partition(day) select empno,ename,job,mgr,hiredate,sal,comm,day from bigdata_emp;</span><br></pre></td></tr></table></figure>
<p>分隔符<br>    <em>log日志里面字段与字段之间的分隔符是什么</em><br>    生产中用的比较多分隔符: ‘,’或\t(Tab)</p>
<h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>
    </div>

    <div>全文完。</div>
  </article>
  <div class="toc-container">
    <div id="toc-div" class="toc-article" >
   <strong class="toc-title">Index</strong>
     
       <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive介绍"><span class="toc-text">Hive介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive架构"><span class="toc-text">Hive架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#元数据"><span class="toc-text">元数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#用户接口"><span class="toc-text">用户接口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SQL-Parser-解析器"><span class="toc-text">SQL Parser(解析器)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Physical-Plan-编译器"><span class="toc-text">Physical Plan(编译器)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Query-Optimizer-优化器"><span class="toc-text">Query Optimizer(优化器)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Execution-执行器"><span class="toc-text">Execution(执行器)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS"><span class="toc-text">HDFS</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive和数据库比较"><span class="toc-text">Hive和数据库比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#部署"><span class="toc-text">部署</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive配置参数"><span class="toc-text">Hive配置参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#显示数据库和表头"><span class="toc-text">显示数据库和表头</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hive数据库存储路径"><span class="toc-text">hive数据库存储路径</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-log存储路径"><span class="toc-text">Hive log存储路径</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#元数据存储到mysql"><span class="toc-text">元数据存储到mysql</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive里面涉及到参数的问题如何设置呢？"><span class="toc-text">Hive里面涉及到参数的问题如何设置呢？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive中的数据类型"><span class="toc-text">Hive中的数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive基本命令"><span class="toc-text">Hive基本命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DDL-Data-Definition-Language"><span class="toc-text">DDL(Data Definition Language)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#库"><span class="toc-text">库</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#创建数据库"><span class="toc-text">创建数据库</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#查询数据库"><span class="toc-text">查询数据库</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#显示数据库信息"><span class="toc-text">显示数据库信息</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#使用数据库"><span class="toc-text">使用数据库</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#删除数据库"><span class="toc-text">删除数据库</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#表"><span class="toc-text">表</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#显示表"><span class="toc-text">显示表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#查看表结构命令"><span class="toc-text">查看表结构命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#查看建表语句"><span class="toc-text">查看建表语句</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#查看表分区"><span class="toc-text">查看表分区</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#外部表和内部表"><span class="toc-text">外部表和内部表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#创建普通表"><span class="toc-text">创建普通表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#创建分区表"><span class="toc-text">创建分区表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#修改表"><span class="toc-text">修改表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#删除表"><span class="toc-text">删除表</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DML-Data-Definition-Language"><span class="toc-text">DML(Data Definition Language)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#load加载数据"><span class="toc-text">load加载数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#insert加载数据"><span class="toc-text">insert加载数据</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结束"><span class="toc-text">结束</span></a></li></ol>
     
</div>
  </div>
</div>
<div class="copyright">
    <span>本作品采用</span>
    <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener">知识共享署名 4.0 国际许可协议</a>
    <span>进行许可。 转载时请注明原文链接。</span>
</div>
<div class="share" style="width: 100%;">
  <img src="https://kevinofneu-blog-static.oss-cn-beijing.aliyuncs.com/static/2018-12-10-qrcode_for_gh_ffacf5722095_258.jpg" alt="Running Geek" style="margin: auto; display: block;"/>

  <div style="margin: auto; text-align: center; font-size: 0.8em; color: grey;">老铁们关注走一走，不迷路</div>
  
</div>

  
    <div class="post-nav">
      <div class="post-nav-item post-nav-next">
        
          <span>〈 </span>
          <a href="/2016/07/02/hadoop/Yarn/" rel="next" title="Yarn">
          Yarn
          </a>
        
      </div>
  
      <div class="post-nav-item post-nav-prev">
          
          <a href="/2016/07/12/hive/Hive%20SQL/" rel="prev" title="Hive Sql">
            Hive Sql
          </a>
          <span>〉</span>
        
      </div>
    </div>
  


    </div>

    

  </div>
  <footer class="footer text-center">
    <div id="bottom-inner">
        <a class="bottom-item" href="https://blog.0xff000000.com" target="_blank" rel="noopener">首页</a> |
        <a class="bottom-item" href="https://0xff000000.com" target="_blank">主站</a> |
        <a class="bottom-item" href="https://github.com/KevinOfNeu" target="_blank">GitHub</a> |
        <a class="bottom-item" href="https://hexo.io" target="_blank">Powered by hexo</a> |
        <a class="bottom-item" href="https://github.com/KevinOfNeu/hexo-theme-xoxo" target="_blank">Theme xoxo</a>
    </div>
</footer>
  

<script>
  (function(window, document, undefined) {

    var timer = null;

    function returnTop() {
      cancelAnimationFrame(timer);
      timer = requestAnimationFrame(function fn() {
        var oTop = document.body.scrollTop || document.documentElement.scrollTop;
        if (oTop > 0) {
          document.body.scrollTop = document.documentElement.scrollTop = oTop - 50;
          timer = requestAnimationFrame(fn);
        } else {
          cancelAnimationFrame(timer);
        }
      });
    }

    var hearts = [];
    window.requestAnimationFrame = (function() {
      return window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.oRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        function(callback) {
          setTimeout(callback, 1000 / 60);
        }
    })();
    init();

    function init() {
      css(".heart{z-index:9999;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: absolute;}.heart:after{top: -5px;}.heart:before{left: -5px;}");
      attachEvent();
      gameloop();
      addMenuEvent();
    }

    function gameloop() {
      for (var i = 0; i < hearts.length; i++) {
        if (hearts[i].alpha <= 0) {
          document.body.removeChild(hearts[i].el);
          hearts.splice(i, 1);
          continue;
        }
        hearts[i].y--;
        hearts[i].scale += 0.004;
        hearts[i].alpha -= 0.013;
        hearts[i].el.style.cssText = "left:" + hearts[i].x + "px;top:" + hearts[i].y + "px;opacity:" + hearts[i].alpha + ";transform:scale(" + hearts[i].scale + "," + hearts[i].scale + ") rotate(45deg);background:" + hearts[i].color;
      }
      requestAnimationFrame(gameloop);
    }

    /**
     * 给logo设置点击事件
     * 
     * - 回到顶部
     * - 出现爱心
     */
    function attachEvent() {
      var old = typeof window.onclick === "function" && window.onclick;
      var logo = document.getElementById("logo");
      if (logo) {
        logo.onclick = function(event) {
          returnTop();
          old && old();
          createHeart(event);
        }
      }
      
    }

    function createHeart(event) {
      var d = document.createElement("div");
      d.className = "heart";
      hearts.push({
        el: d,
        x: event.clientX - 5,
        y: event.clientY - 5,
        scale: 1,
        alpha: 1,
        color: randomColor()
      });
      document.body.appendChild(d);
    }

    function css(css) {
      var style = document.createElement("style");
      style.type = "text/css";
      try {
        style.appendChild(document.createTextNode(css));
      } catch (ex) {
        style.styleSheet.cssText = css;
      }
      document.getElementsByTagName('head')[0].appendChild(style);
    }

    function randomColor() {
      // return "rgb(" + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + ")";
      return "#F44336";
    }

    function addMenuEvent() {
      var menu = document.getElementById('menu-main-post');
      if (menu) {
        var toc = document.getElementById('toc');
        if (toc) {
          menu.onclick = function() {
            if (toc) {
              if (toc.style.display == 'block') {
                toc.style.display = 'none';
              } else {
                toc.style.display = 'block';
              }
            }
          };
        } else {
          menu.style.display = 'none';
        }
      }
    }

  })(window, document);
</script>

  



</body>
</html>
