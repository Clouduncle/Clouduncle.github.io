
<!DOCTYPE html>
<html lang="zh-CN">


<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <meta name="theme-color" content="#202020"/>
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
  
  
    <meta name="keywords" content="hadoop," />
  

  
    <meta name="description" content="一起成长" />
  
  
  <link rel="icon" type="image/x-icon" href="/logo.png">
  <title>hadoop介绍 [ 小彩鸟 ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css">
    
      <link rel="stylesheet" href="/css/xoxo.css">
    
  
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <div class="nav-container">
    <nav class="home-menu pure-menu pure-menu-horizontal">
  <a class="pure-menu-heading" href="/">
    <img class="avatar" src="/images/logo.png">
    <span class="title">小彩鸟</span>
  </a>

  <ul class="pure-menu-list clearfix">
      
          
            <li class="pure-menu-item"><a href="/" class="pure-menu-link">首页</a></li>
          
      
          
            <li class="pure-menu-item"><a href="/archives" class="pure-menu-link">归档</a></li>
          
      
          
            <li class="pure-menu-item"><a href="/tags" class="pure-menu-link">标签</a></li>
          
      
          
            <li class="pure-menu-item"><a href="/search" class="pure-menu-link">搜索</a></li>
          
      
  </ul>
   
</nav>
  </div>

  <div class="container" id="content-outer">
    <div class="inner" id="content-inner">
      <div class="post-container">
  <article class="post" id="post">
    <header class="post-header text-center">
      <h1 class="title">
        hadoop介绍
      </h1>
      <span>
        
        <time class="time" datetime="2016-05-21T04:00:00.000Z">
        2016-05-21
      </time>
        
      </span>
      <span class="slash">/</span>
      <span class="post-meta">
      <span class="post-tags">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/" rel="tag">hadoop</a></li></ul>
      </span>
    </span>
      <span class="slash">/</span>
      <span class="read">
      <span id="busuanzi_value_page_pv"></span> 点击
    </span>
      <span class="slash">/</span>
    </header>

    <div class="post-content">
      <h1 id="hadoop定义"><a href="#hadoop定义" class="headerlink" title="hadoop定义"></a>hadoop定义</h1><p>hadoop</p>
<ul>
<li>广义:以Apache hadoop软件为主的生态圈 也包含了hive sqoop hbase kafka spark flink等</li>
<li>狭义:就是Apache hadoop软件包括:hdfs(存储) mapreduce(计算) yarn(资源和作业调度)</li>
</ul>
<p>大数据平台: <em>存储是第一位因为如果数据丢了或者不准确，计算再厉害指标都会不准确</em>，要考虑如果存储挂了在其他地方还能不能找到原始数据，不要数据一存储到hdfs就把原始数据删除了，至少近期的要压缩后保存一阵，或者冷数据迁移走放到阿里云的oss存储上</p>
<p>官网: 大数据组件大多数都是Apach的<br>&emsp;&emsp;hadoop.apache.org<br>&emsp;&emsp;hadoop.hive.org<br>&emsp;&emsp;…</p>
<p>2020:生产上至今企业还是以CDH5.x为主(cloudera公司)可以傻瓜式安装 . 在6.3.3版本后采取了付费模式，这点不用担心目前生产上还可以是CDH5.x够用了，求稳<br>对于CDH不用升级，升级是升级里面的组件hadoop和spark，这个很简单升级</p>
<p>hadoop-2.6.0-cdh5.16.2.tar.gz  (CDH版本已经很新了为什么hadoop版本还是2.6.0，因为CDH公司在发布版本后已经打了很多补丁，它的2.6.0完全可以媲美apache hadoop的2.9)</p>
<p>生产注意点:<br><a href="https://cwiki.apache.org/confluence/display/HADOOP2/HadoopJavaVersions" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/HADOOP2/HadoopJavaVersions</a><br><a href="https://docs.cloudera.com/documentation/enterprise/release-notes/topics/rn_consolidated_pcm.html#pcm_jdk" target="_blank" rel="noopener">https://docs.cloudera.com/documentation/enterprise/release-notes/topics/rn_consolidated_pcm.html#pcm_jdk</a> (标注了cdh推荐的jdk版本..)</p>
<h1 id="hadoop安装"><a href="#hadoop安装" class="headerlink" title="hadoop安装"></a>hadoop安装</h1><h2 id="简单的集群搭建过程"><a href="#简单的集群搭建过程" class="headerlink" title="简单的集群搭建过程"></a>简单的集群搭建过程</h2><ul>
<li>JDK 安装</li>
<li>配置 SSH 免密登录</li>
<li>配置 hadoop 核心文件</li>
<li>格式化 namenode</li>
</ul>
<h2 id="hadoop核心文件"><a href="#hadoop核心文件" class="headerlink" title="hadoop核心文件"></a>hadoop核心文件</h2><h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdfs:&#x2F;&#x2F;hadoop102:9000&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;data&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">   &lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">       &lt;value&gt;hdfs:&#x2F;&#x2F;hadoop102:9000&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">	&lt;value&gt;&#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;data&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">   &lt;!-- 指定mr运行在yarn上 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">	&lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a>slaves</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure>
<h3 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_144</span><br><span class="line">#hadoop修改pid文件的存储目录</span><br><span class="line">export HADOOP_PID_DIR&#x3D;&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;</span><br></pre></td></tr></table></figure>
<h3 id="yarn-env-sh"><a href="#yarn-env-sh" class="headerlink" title="yarn-env.sh"></a>yarn-env.sh</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_144</span><br></pre></td></tr></table></figure>
<h3 id="mapred-env-sh"><a href="#mapred-env-sh" class="headerlink" title="mapred-env.sh"></a>mapred-env.sh</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_144</span><br></pre></td></tr></table></figure>

<h2 id="jps"><a href="#jps" class="headerlink" title="jps"></a>jps</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br><span class="line">21712 DataNode</span><br><span class="line">21585 NameNode</span><br><span class="line">23989 ResourceManager</span><br><span class="line">29877 Jps</span><br><span class="line">24094 NodeManager</span><br><span class="line">21871 SecondaryNameNode</span><br></pre></td></tr></table></figure>
<p>根据nn的进程号查看占用端口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ netstat -nlp| grep  21585 </span><br><span class="line">执行后发现 50070和9000，其中50070是web界面</span><br></pre></td></tr></table></figure>

<p>如果进程起不来，不管hdfs还是yarn，要先看日志是否有error，启动的时候命令行会打印出日志的地址，我们的hadoop安装目录的logs下</p>
<p>hadoop启动后对应的进程标识文件存储位置：/tmp/hsperfdata_所属用户<br>之后jps是查询该文件夹下文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 tmp]$ cd hsperfdata_hadoop</span><br><span class="line">[hadoop@hadoop001 hsperfdata_hadoop]$ ll</span><br><span class="line">total 160</span><br><span class="line">-rw------- 1 hadoop hadoop 32768 May  9 22:01 21585</span><br><span class="line">-rw------- 1 hadoop hadoop 32768 May  9 22:01 21712</span><br><span class="line">-rw------- 1 hadoop hadoop 32768 May  9 22:01 21871</span><br><span class="line">-rw------- 1 hadoop hadoop 32768 May  9 22:01 23989</span><br><span class="line">-rw------- 1 hadoop hadoop 32768 May  9 22:01 24094</span><br><span class="line">[hadoop@hadoop001 hsperfdata_hadoop]$ mv 21712 21712.bak</span><br><span class="line">[hadoop@hadoop001 hsperfdata_hadoop]$</span><br></pre></td></tr></table></figure>
<p>修改其中的一个进程文件后</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br><span class="line">21585 NameNode</span><br><span class="line">23989 ResourceManager</span><br><span class="line">30358 Jps</span><br><span class="line">24094 NodeManager</span><br><span class="line">21871 SecondaryNameNode</span><br><span class="line">[hadoop@hadoop001 hadoop]$ </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[hadoop@hadoop001 hsperfdata_hadoop]$ ps -ef|grep DataNode</span><br><span class="line">hadoop   21712     1  0 May06 ?        00:03:54 &#x2F;usr&#x2F;java&#x2F;jdk1.8.0_181&#x2F;bin&#x2F;java -Dproc_datanode -Xmx1000m -Djava.net.preferIPv4Stack&#x3D;true -Dhadoop.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;app&#x2F;hadoop-2.6.0-cdh5.16.2&#x2F;logs -Dhadoop.log.file&#x3D;hadoop.log -Dhadoop.home.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;app&#x2F;hadoop-2.6.0-cdh5.16.2 -Dhadoop.id.str&#x3D;hadoop -Dhadoop.root.logger&#x3D;INFO，console -Djava.library.path&#x3D;&#x2F;home&#x2F;hadoop&#x2F;app&#x2F;hadoop-2.6.0-cdh5.16.2&#x2F;lib&#x2F;native -Dhadoop.policy.file&#x3D;hadoop-policy.xml -Djava.net.preferIPv4Stack&#x3D;true -Djava.net.preferIPv4Stack&#x3D;true -Djava.net.preferIPv4Stack&#x3D;true -Dhadoop.log.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;app&#x2F;hadoop-2.6.0-cdh5.16.2&#x2F;logs -Dhadoop.log.file&#x3D;hadoop-hadoop-datanode-hadoop001.log -Dhadoop.home.dir&#x3D;&#x2F;home&#x2F;hadoop&#x2F;app&#x2F;hadoop-2.6.0-cdh5.16.2 -Dhadoop.id.str&#x3D;hadoop -Dhadoop.root.logger&#x3D;INFO，RFA -Djava.library.path&#x3D;&#x2F;home&#x2F;hadoop&#x2F;app&#x2F;hadoop-2.6.0-cdh5.16.2&#x2F;lib&#x2F;native -Dhadoop.policy.file&#x3D;hadoop-policy.xml -Djava.net.preferIPv4Stack&#x3D;true -server -Dhadoop.security.logger&#x3D;ERROR，RFAS -Dhadoop.security.logger&#x3D;ERROR，RFAS -Dhadoop.security.logger&#x3D;ERROR，RFAS -Dhadoop.security.logger&#x3D;INFO，RFAS org.apache.hadoop.hdfs.server.datanode.DataNode</span><br><span class="line">hadoop   30469 30251  0 22:03 pts&#x2F;1    00:00:00 grep --color&#x3D;auto DataNode</span><br><span class="line">[hadoop@hadoop001 hsperfdata_hadoop]$</span><br></pre></td></tr></table></figure>

<p>上述/tmp/hsperfdata_hadoop/21712文件被移走了，之后jps就不再显示datanode了，但是datanode的进程是在的。所以如果脚本使用jps进行监控，如果上述文件丢失那么jps是找不到进程的，会造成生产的误报，实际ps -ef查询这个进程是存在的<br>但是这个文件被移除并不影响程序的停止和启动</p>
<p><em>注意如果jps后出现 进程号 – process information unavailable</em> 此时该进程并不能断定就不存在了，jsp是存在误报情况的，需要ps -ef|grep 进程号 判断是否进程真的存在<br><em>所以准确判定进程是否存在，通过 ps -ef统计.不要被jps误导</em></p>
<h4 id="hadoop的pid文件"><a href="#hadoop的pid文件" class="headerlink" title="hadoop的pid文件"></a>hadoop的pid文件</h4><h5 id="存储位置"><a href="#存储位置" class="headerlink" title="存储位置"></a>存储位置</h5><p>&emsp;&emsp;默认是存储在/tmp目录，pid文件内容是进程的pid号。在进程启动后，pid向pid文件写入进程的pid号，进程关闭时会从pid文件读出pid数字，然后kill -9 pid，关闭后再删除对应进程对应的pid文件，所以文件如果不小心被删除会出现问题</p>
<p>&emsp;&emsp;生产中pid文件真的可以放心的丢到/tmp维护吗????<br>&emsp;&emsp;这是不可以的，因为linux的/tmp目录会有30天的默认删除机制，如果存在超过30天文件就会被删除，我们假设rm的pid文件被删除了，如果被系统删掉了，之后我们想关闭yarn(rm，nm)执行sbin/stop-yarn.sh，nm正常关闭对应的pid文件被删除，rm就会报错显示没有对应的pid号自然对应的pid文件也不会被删除，但是实际后台这个进程是存在的。之后如果我们没有手动关闭进程并删除对应pid文件，此时启动yarn，那么yarn会智能判定是否存在进程rm，nm如果存在就不会创建对应进程，但是会创建pid文件，这个pid文件保存的pid号并不是之前没有关闭的，这个pid号实际没有对应的进程启动，所以还是紊乱的，这是恶性循环即我的rm永远不会通过我的命令来关闭</p>
<p>总结：生产上pid文件不要丢在/tmp目录，这会影响进程的启动和停止。如果工作中发现机器进程没有重启成功，新改的配置没有应用上，此时我们应该查看后台实际的进程号和pid文件里保存的进程号是否一致。</p>
<h5 id="hadoop修改pid文件的存储目录"><a href="#hadoop修改pid文件的存储目录" class="headerlink" title="hadoop修改pid文件的存储目录"></a>hadoop修改pid文件的存储目录</h5><p>在公司最开始没有调这个pid的，出现故障后才开始调整<br>在hadoop-env.sh脚本<br>export HADOOP_PID_DIR=/home/hadoop/tmp/</p>

    </div>

    <div>全文完。</div>
  </article>
  <div class="toc-container">
    <div id="toc-div" class="toc-article" >
   <strong class="toc-title">Index</strong>
     
       <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#hadoop定义"><span class="toc-text">hadoop定义</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hadoop安装"><span class="toc-text">hadoop安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简单的集群搭建过程"><span class="toc-text">简单的集群搭建过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop核心文件"><span class="toc-text">hadoop核心文件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#core-site-xml"><span class="toc-text">core-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hdfs-site-xml"><span class="toc-text">hdfs-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#yarn-site-xml"><span class="toc-text">yarn-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mapred-site-xml"><span class="toc-text">mapred-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#slaves"><span class="toc-text">slaves</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hadoop-env-sh"><span class="toc-text">hadoop-env.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#yarn-env-sh"><span class="toc-text">yarn-env.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mapred-env-sh"><span class="toc-text">mapred-env.sh</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#jps"><span class="toc-text">jps</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#hadoop的pid文件"><span class="toc-text">hadoop的pid文件</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#存储位置"><span class="toc-text">存储位置</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#hadoop修改pid文件的存储目录"><span class="toc-text">hadoop修改pid文件的存储目录</span></a></li></ol></li></ol></li></ol></li></ol></li></ol>
     
</div>
  </div>
</div>
<div class="copyright">
    <span>本作品采用</span>
    <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener">知识共享署名 4.0 国际许可协议</a>
    <span>进行许可。 转载时请注明原文链接。</span>
</div>
<div class="share" style="width: 100%;">
  <img src="https://kevinofneu-blog-static.oss-cn-beijing.aliyuncs.com/static/2018-12-10-qrcode_for_gh_ffacf5722095_258.jpg" alt="Running Geek" style="margin: auto; display: block;"/>

  <div style="margin: auto; text-align: center; font-size: 0.8em; color: grey;">老铁们关注走一走，不迷路</div>
  
</div>

  
    <div class="post-nav">
      <div class="post-nav-item post-nav-next">
        
          <span>〈 </span>
          <a href="/2015/07/28/java/java%E5%B0%81%E8%A3%85%E7%BB%A7%E6%89%BF%E5%A4%9A%E6%80%81/" rel="next" title="java">
          java
          </a>
        
      </div>
  
      <div class="post-nav-item post-nav-prev">
          
          <a href="/2016/06/01/hadoop/hdfs/" rel="prev" title="HDFS">
            HDFS
          </a>
          <span>〉</span>
        
      </div>
    </div>
  


    </div>

    

  </div>
  <footer class="footer text-center">
    <div id="bottom-inner">
        <a class="bottom-item" href="https://blog.0xff000000.com" target="_blank" rel="noopener">首页</a> |
        <a class="bottom-item" href="https://0xff000000.com" target="_blank">主站</a> |
        <a class="bottom-item" href="https://github.com/KevinOfNeu" target="_blank">GitHub</a> |
        <a class="bottom-item" href="https://hexo.io" target="_blank">Powered by hexo</a> |
        <a class="bottom-item" href="https://github.com/KevinOfNeu/hexo-theme-xoxo" target="_blank">Theme xoxo</a>
    </div>
</footer>
  

<script>
  (function(window, document, undefined) {

    var timer = null;

    function returnTop() {
      cancelAnimationFrame(timer);
      timer = requestAnimationFrame(function fn() {
        var oTop = document.body.scrollTop || document.documentElement.scrollTop;
        if (oTop > 0) {
          document.body.scrollTop = document.documentElement.scrollTop = oTop - 50;
          timer = requestAnimationFrame(fn);
        } else {
          cancelAnimationFrame(timer);
        }
      });
    }

    var hearts = [];
    window.requestAnimationFrame = (function() {
      return window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.oRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        function(callback) {
          setTimeout(callback, 1000 / 60);
        }
    })();
    init();

    function init() {
      css(".heart{z-index:9999;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: absolute;}.heart:after{top: -5px;}.heart:before{left: -5px;}");
      attachEvent();
      gameloop();
      addMenuEvent();
    }

    function gameloop() {
      for (var i = 0; i < hearts.length; i++) {
        if (hearts[i].alpha <= 0) {
          document.body.removeChild(hearts[i].el);
          hearts.splice(i, 1);
          continue;
        }
        hearts[i].y--;
        hearts[i].scale += 0.004;
        hearts[i].alpha -= 0.013;
        hearts[i].el.style.cssText = "left:" + hearts[i].x + "px;top:" + hearts[i].y + "px;opacity:" + hearts[i].alpha + ";transform:scale(" + hearts[i].scale + "," + hearts[i].scale + ") rotate(45deg);background:" + hearts[i].color;
      }
      requestAnimationFrame(gameloop);
    }

    /**
     * 给logo设置点击事件
     * 
     * - 回到顶部
     * - 出现爱心
     */
    function attachEvent() {
      var old = typeof window.onclick === "function" && window.onclick;
      var logo = document.getElementById("logo");
      if (logo) {
        logo.onclick = function(event) {
          returnTop();
          old && old();
          createHeart(event);
        }
      }
      
    }

    function createHeart(event) {
      var d = document.createElement("div");
      d.className = "heart";
      hearts.push({
        el: d,
        x: event.clientX - 5,
        y: event.clientY - 5,
        scale: 1,
        alpha: 1,
        color: randomColor()
      });
      document.body.appendChild(d);
    }

    function css(css) {
      var style = document.createElement("style");
      style.type = "text/css";
      try {
        style.appendChild(document.createTextNode(css));
      } catch (ex) {
        style.styleSheet.cssText = css;
      }
      document.getElementsByTagName('head')[0].appendChild(style);
    }

    function randomColor() {
      // return "rgb(" + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + ")";
      return "#F44336";
    }

    function addMenuEvent() {
      var menu = document.getElementById('menu-main-post');
      if (menu) {
        var toc = document.getElementById('toc');
        if (toc) {
          menu.onclick = function() {
            if (toc) {
              if (toc.style.display == 'block') {
                toc.style.display = 'none';
              } else {
                toc.style.display = 'block';
              }
            }
          };
        } else {
          menu.style.display = 'none';
        }
      }
    }

  })(window, document);
</script>

  



</body>
</html>
